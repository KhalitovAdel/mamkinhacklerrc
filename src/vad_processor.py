# vad_processor.py
import webrtcvad
import struct
import numpy as np
from collections import deque
from scipy import signal

class VADProcessor:
    def __init__(self, sample_rate=16000, channels=1, aggressiveness=3):
        self.vad = webrtcvad.Vad(aggressiveness)
        self.SAMPLE_RATE = sample_rate
        self.CHANNELS = channels
        self.FRAME_DURATION = 30  # ms
        self.CHUNK_SIZE = int(self.SAMPLE_RATE * self.FRAME_DURATION / 1000)
        
        # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –±—É—Ñ–µ—Ä (–¥–æ 60 —Å–µ–∫—É–Ω–¥)
        self.audio_buffer = deque(maxlen=int(60 * 1000 / self.FRAME_DURATION))
        self.is_speaking = False
        self.silence_frames = 0
        self.MIN_SILENCE_FRAMES = 25  # –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–ª—è —à—É–º–Ω—ã—Ö —Å—Ä–µ–¥
        self.noise_level = None
        self.speech_counter = 0

    def process_audio_chunk(self, chunk):
        """Process audio chunk with noise adaptation"""
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ –º–æ–Ω–æ
        if self.CHANNELS == 2:
            chunk = self.__convert_stereo_to_mono(chunk)
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª—è —à—É–º–∞
        self.__update_noise_profile(chunk)
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —à—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏—è
        processed_chunk = self.__apply_noise_reduction(chunk)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ VAD —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º –ø–æ—Ä–æ–≥–æ–º
        is_speech = self.vad.is_speech(processed_chunk, self.SAMPLE_RATE)
        
        # –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–µ—á–∏
        if is_speech:
            self.speech_counter += 1
            self.audio_buffer.append(chunk)  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π chunk
            self.silence_frames = 0
            
            if not self.is_speaking and self.speech_counter > 2:
                print("üîä Speech started!")
                self.is_speaking = True
                return "start"
        else:
            if self.is_speaking:
                self.silence_frames += 1
                
                # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –ø–æ—Ä–æ–≥ —Ç–∏—à–∏–Ω—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —É—Ä–æ–≤–Ω—è —à—É–º–∞
                dynamic_threshold = self.MIN_SILENCE_FRAMES
                if self.noise_level and self.noise_level > 2000:  # –í—ã—Å–æ–∫–∏–π —à—É–º
                    dynamic_threshold += 10
                
                if self.silence_frames >= dynamic_threshold:
                    print(f"üîá Speech ended! (Noise level: {self.noise_level:.1f})")
                    self.is_speaking = False
                    self.speech_counter = 0
                    audio_data = b"".join(self.audio_buffer)
                    self.audio_buffer.clear()
                    return "end", audio_data
        
        return None

    def __apply_noise_reduction(self, chunk):
        """–ü—Ä–æ—Å—Ç–æ–µ —à—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ"""
        samples = np.frombuffer(chunk, dtype=np.int16)
        
        # –ë–∞–∑–æ–≤–æ–µ —à—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ (—Ñ–∏–ª—å—Ç—Ä –≤—ã—Å–æ–∫–∏—Ö —á–∞—Å—Ç–æ—Ç)
        b, a = signal.butter(5, 300/(self.SAMPLE_RATE/2), 'high')
        filtered = signal.filtfilt(b, a, samples)
        
        return filtered.astype(np.int16).tobytes()

    def __convert_stereo_to_mono(self, data):
        """Convert stereo to mono with noise-aware mixing"""
        samples = struct.unpack(f"<{len(data)//2}h", data)
        mono_data = bytearray()
        
        for i in range(0, len(samples), 2):
            l = samples[i]
            r = samples[i+1] if i+1 < len(samples) else l
            
            # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å–º–µ—à–∏–≤–∞–Ω–∏–µ —Å —É—á–µ—Ç–æ–º —É—Ä–æ–≤–Ω—è —Å–∏–≥–Ω–∞–ª–∞
            if abs(l) > abs(r):
                mono_sample = int(l * 0.7 + r * 0.3)
            else:
                mono_sample = int(l * 0.3 + r * 0.7)
                
            mono_data.extend(struct.pack("<h", mono_sample))
        
        return bytes(mono_data)

    def __update_noise_profile(self, chunk):
        """–ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ —É—Ä–æ–≤–Ω—è —à—É–º–∞"""
        samples = np.frombuffer(chunk, dtype=np.int16)
        current_level = np.mean(np.abs(samples))
        
        if self.noise_level is None:
            self.noise_level = current_level
        else:
            # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ
            self.noise_level = 0.9 * self.noise_level + 0.1 * current_level